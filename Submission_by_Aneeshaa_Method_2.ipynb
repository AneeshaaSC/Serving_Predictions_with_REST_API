{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method -2 : Using Docker container\n",
    "\n",
    "I've installed docker-ce on my local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q requests\n",
    "\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model in the required format to get protobuf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5model = keras.models.load_model(\"C:/Users/AChowdhry/Desktop/cookpad\\model/0000001/tomato_model.h5\",compile=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\AChowdhry\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: C:/Users/AChowdhry/Desktop/cookpad/model/0000002/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(h5model, \"C:/Users/AChowdhry/Desktop/cookpad/model/0000002/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the TensorFlow Serving Docker image and repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'serving' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone --recursive https://github.com/tensorflow/serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default tag: latest\n",
      "latest: Pulling from tensorflow/serving\n",
      "Digest: sha256:a94b7e3b0e825350675e83b0c2f2fc28f34be358c34e4126a1d828de899ec44f\n",
      "Status: Image is up to date for tensorflow/serving:latest\n",
      "docker.io/tensorflow/serving:latest\n"
     ]
    }
   ],
   "source": [
    "!docker pull tensorflow/serving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mounting the on the container so TF Serving can read the model from inside the container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using os.system to run the command as background processes are not supported. \n",
    "\n",
    "Found that running this using os.system causes entering a NET_LOG loop and remains that way not allowing execution of subsequent commands. Hence I terminated the os.system cell, started docker container locally using docker desktop.\n",
    "\n",
    "\n",
    "This command will start a docker container, deploy the model and make a REST endpoint available to get predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "commandstring = \"docker run -p 8501:8501 --name cookpad --mount type=bind,source=C:/Users/AChowdhry/Desktop/cookpad/model/,target=/models/saved_model.pb -e MODEL_NAME=saved_model.pb -t tensorflow/serving &\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(commandstring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sending three samples for inference - taken from inference.py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_dataset = [\n",
    "    [5.1, 3.3, 1.7, 0.5, ],\n",
    "    [5.9, 3.0, 4.2, 1.5, ],\n",
    "    [6.9, 3.1, 5.4, 2.1]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: {\"signature_name\": \"serving_default\", \"instances\": ... , 0.5], [5.9, 3.0, 4.2, 1.5], [6.9, 3.1, 5.4, 2.1]]}\n"
     ]
    }
   ],
   "source": [
    "#json format for api calls\n",
    "data = json.dumps({\"signature_name\": \"serving_default\", \"instances\": predict_dataset})\n",
    "print('Data: {} ... {}'.format(data[:50], data[len(data)-52:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['Plum', 'Cherry', 'BeefSteak']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\"content-type\": \"application/json\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post query which will send the served model the above instances or examples and get back predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_response = requests.post('http://localhost:8501/v1/models/saved_model.pb:predict', data=data, headers=headers,verify=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "apipredictions = json.loads(json_response.text)['predictions']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plum 0\n",
      "Cherry 1\n",
      "BeefSteak 2\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(apipredictions)):\n",
    "    print(class_names[np.argmax(apipredictions[i])], np.argmax(apipredictions[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
